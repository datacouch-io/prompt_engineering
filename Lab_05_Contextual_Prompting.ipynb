{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_muU39wb8fW6"
      },
      "source": [
        "# Lab 5: Contextual Prompting\n",
        "\n",
        "Welcome to Lab 5! In this lab, we will discuss contextual prompting a technique to improve relevance and quality in AI-generated responses. Now, by learning to use context effectively, you will know how much information you need to provide for an AI model to produce the best results.\n",
        "\n",
        "**Why This Matters:**\n",
        "AI models, including language models, do better with proper background information. However, it is the delicate balance between providing sufficient context and avoiding overwhelming information that, most of the time creates the most prominent challenge.\n",
        "\n",
        "**Learning Objectives:**\n",
        "- Understand how context affects prompt outcomes.\n",
        "- Develop skills to manage and structure long prompts effectively.\n",
        "- Experiment with real-world scenarios to apply contextual prompting techniques.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV4rszpg8fW9"
      },
      "source": [
        "## Setting Up the OpenAI API\n",
        "\n",
        "Before we begin, you'll need to set up access to the OpenAI API. Make sure your API key is properly configured.\n",
        "\n",
        "**Code Example:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIGTL4CX8fW-"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "# Store your OpenAI API key\n",
        "openai.api_key = \"your-api-key-here\"\n",
        "\n",
        "# Test the setup by making a simple API request\n",
        "response = openai.Completion.create(\n",
        "    engine=\"gpt-4\",\n",
        "    prompt=\"Say hello to the world!\",\n",
        "    max_tokens=5\n",
        ")\n",
        "print(response.choices[0].text.strip())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w8rauRD8fXA"
      },
      "source": [
        "## Section 1: Contextual Prompt Basics\n",
        "\n",
        "Giving a prompt with context could lead to an enormous difference in the quality and relevance of AI's response. In this section, we will start from the basics and work up to the more complex situations.\n",
        "\n",
        "### What is Contextual Prompting?\n",
        "Contextual prompting involves providing additional background information to an AI model to guide its response. This context can be explicit (e.g., specifying details in the prompt) or implicit (e.g., structuring the prompt in a way that hints at the needed information).\n",
        "\n",
        "**Example:** Imagine asking an AI for advice on what to wear. Here, context would be about the weather, the occasion, or your style. Advice without context only makes it very generic.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFkrejue8fXB"
      },
      "outputs": [],
      "source": [
        "# Example of a simple prompt without context\n",
        "prompt_no_context = \"What is the capital of France?\"\n",
        "\n",
        "# Example of a prompt with added context\n",
        "prompt_with_context = \"I am planning a trip to Europe. Can you tell me the capital of France?\"\n",
        "\n",
        "# Generating responses using the OpenAI API\n",
        "response_no_context = openai.Completion.create(\n",
        "    engine=\"gpt-4\",\n",
        "    prompt=prompt_no_context,\n",
        "    max_tokens=10\n",
        ").choices[0].text.strip()\n",
        "\n",
        "response_with_context = openai.Completion.create(\n",
        "    engine=\"gpt-4\",\n",
        "    prompt=prompt_with_context,\n",
        "    max_tokens=10\n",
        ").choices[0].text.strip()\n",
        "\n",
        "# Displaying the responses\n",
        "print(\"Response without context:\", response_no_context)\n",
        "print(\"Response with context:\", response_with_context)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjKNTw0I8fXB"
      },
      "source": [
        "### Exercise 1: Crafting Contextual Prompts\n",
        "\n",
        "Let's start by crafting your own contextual prompts. Consider the following scenario:\n",
        "\n",
        "**Scenario:** You are asking an AI for a restaurant recommendation.\n",
        "\n",
        "**Initial Prompt:** \"Can you recommend a restaurant?\"\n",
        "\n",
        "**Task:** Modify the prompt by adding relevant context such as cuisine preferences, location, and occasion.\n",
        "\n",
        "**Your Contextual Prompt:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HiUIaOt8fXC"
      },
      "outputs": [],
      "source": [
        "# Your modified prompt\n",
        "contextual_prompt = \"I'm looking for a cozy Italian restaurant in downtown Manhattan for a dinner date. Any recommendations?\"\n",
        "\n",
        "# Generating the response\n",
        "response_contextual = openai.Completion.create(\n",
        "    engine=\"gpt-4\",\n",
        "    prompt=contextual_prompt,\n",
        "    max_tokens=50\n",
        ").choices[0].text.strip()\n",
        "\n",
        "# Displaying the response\n",
        "print(\"Response with context:\", response_contextual)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmB3yfFj8fXC"
      },
      "source": [
        "### Discussion:\n",
        "\n",
        "How did adding context change the response? What details did the AI consider in its recommendation? Discuss your observations with a partner or in a group, if applicable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsIjNzaZ8fXD"
      },
      "source": [
        "## Section 2: Managing Long Prompts\n",
        "\n",
        "Long prompts are large in information, but not all of this information is usually necessary to make the AI generate a useful reply. In this unit, you'll learn how to locate important bits of information in a long prompt and condense a long prompt without losing key context.\n",
        "\n",
        "### Why Managing Long Prompts is Crucial\n",
        "- **Cognitive Load:** Too much information can overwhelm the AI, leading to less accurate or relevant responses.\n",
        "- **Efficiency:** Shorter, more focused prompts tend to yield quicker and more precise results.\n",
        "\n",
        "**Case Study:** A long prompt might include a character’s entire backstory when all that's needed is their current situation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGhB8krQ8fXE"
      },
      "outputs": [],
      "source": [
        "# Example of a long prompt with unnecessary details\n",
        "long_prompt = \"\"\"\n",
        "I'm writing a novel set in early 19th-century France, with the protagonist being a young lady who struggles against the control of society and the expectations of her family.\n",
        "Thoughts of running away from home lingered in her head so that she could pursue the dream of becoming a writer, but she lacked a clue on how to.\n",
        "She has heard about Paris full of aspiring writers, but she's afraid of the dangers into which she might fall.\n",
        "Can you indicate what she should do and how she might overcome these challenges?\n",
        "\"\"\"\n",
        "\n",
        "# Refined version of the prompt with essential details\n",
        "refined_prompt = \"\"\"\n",
        "A young woman in early 19th century France is considering moving to Paris to pursue her dream of becoming a writer.\n",
        "Can you suggest how she might overcome the challenges she will face?\n",
        "\"\"\"\n",
        "\n",
        "# Generating responses using the OpenAI API\n",
        "response_long = openai.Completion.create(\n",
        "    engine=\"gpt-4\",\n",
        "    prompt=long_prompt,\n",
        "    max_tokens=150\n",
        ").choices[0].text.strip()\n",
        "\n",
        "response_refined = openai.Completion.create(\n",
        "    engine=\"gpt-4\",\n",
        "    prompt=refined_prompt,\n",
        "    max_tokens=150\n",
        ").choices[0].text.strip()\n",
        "\n",
        "# Displaying the responses\n",
        "print(\"Response to long prompt:\", response_long)\n",
        "print(\"Response to refined prompt:\", response_refined)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXwD-5nP8fXF"
      },
      "source": [
        "### Exercise 2: Condensing Long Prompts\n",
        "\n",
        "**Task:** Given the following long prompt, identify the key elements and create a shorter, more focused version. Then, test both versions to compare the responses.\n",
        "\n",
        "**Original Prompt:**\n",
        "\"I have been feeling very tired and stressed lately. I work long hours at a demanding job, and I haven't had much time to relax or spend with my family.\n",
        "I also have a big project coming up that I am worried about. I am looking for advice on how to manage my stress and balance my work and personal life better.\"\n",
        "\n",
        "**Condensed Prompt:** (Write your version below)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6w-XmQo8fXF"
      },
      "outputs": [],
      "source": [
        "# Condensed prompt based on key elements\n",
        "condensed_prompt = \"\"\"\n",
        "I'm feeling stressed due to long work hours and a big upcoming project.\n",
        "Can you give advice on managing stress and balancing work and personal life?\n",
        "\"\"\"\n",
        "\n",
        "# Generating the response\n",
        "response_condensed = openai.Completion.create(\n",
        "    engine=\"gpt-4\",\n",
        "    prompt=condensed_prompt,\n",
        "    max_tokens=150\n",
        ").choices[0].text.strip()\n",
        "\n",
        "# Displaying the response\n",
        "print(\"Response to condensed prompt:\", response_condensed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXHvuzN_8fXG"
      },
      "source": [
        "### Group Activity:\n",
        "\n",
        "Split into small groups and discuss your condensed prompts. Share your reasoning behind what you chose to keep or remove. How did your group's approaches differ? Did anyone come up with an especially effective prompt?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5OGT3PY8fXG"
      },
      "source": [
        "## Section 3: Contextual Prompting in Practice\n",
        "\n",
        "Now that you’ve learned how to manage context and refine prompts, let’s apply these techniques to real-world scenarios.\n",
        "\n",
        "### Practical Scenario:\n",
        "You are designing an AI assistant for a customer service application. The AI needs to respond to inquiries about order status, product information, and troubleshooting.\n",
        "\n",
        "**Task:** Create prompts for these scenarios, providing enough context to get helpful and accurate responses from the AI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efPAC_z58fXG"
      },
      "outputs": [],
      "source": [
        "# Scenario 1: Order Status Inquiry\n",
        "order_status_prompt = \"\"\"\n",
        "A customer is inquiring about the status of their recent order. The order number is 12345, and it was placed on August 10th.\n",
        "The customer wants to know when they can expect delivery.\n",
        "\"\"\"\n",
        "\n",
        "# Scenario 2: Product Information\n",
        "product_info_prompt = \"\"\"\n",
        "A customer is asking for details about a new smartphone model. They want to know about its features, battery life, and price.\n",
        "\"\"\"\n",
        "\n",
        "# Scenario 3: Troubleshooting\n",
        "troubleshooting_prompt = \"\"\"\n",
        "A customer is having trouble with their laptop not connecting to Wi-Fi. They’ve tried restarting the device and router but still cannot connect.\n",
        "They need help troubleshooting the issue.\n",
        "\"\"\"\n",
        "\n",
        "# Generating responses\n",
        "response_order_status = openai.Completion.create(\n",
        "    engine=\"gpt-4\",\n",
        "    prompt=order_status_prompt,\n",
        "    max_tokens=150\n",
        ").choices[0].text.strip()\n",
        "\n",
        "response_product_info = openai.Completion.create(\n",
        "    engine=\"gpt-4\",\n",
        "    prompt=product_info_prompt,\n",
        "    max_tokens=150\n",
        ").choices[0].text.strip()\n",
        "\n",
        "response_troubleshooting = openai.Completion.create(\n",
        "    engine=\"gpt-4\",\n",
        "    prompt=troubleshooting_prompt,\n",
        "    max_tokens=150\n",
        ").choices[0].text.strip()\n",
        "\n",
        "# Displaying the responses\n",
        "print(\"Response to order status inquiry:\", response_order_status)\n",
        "print(\"Response to product information inquiry:\", response_product_info)\n",
        "print(\"Response to troubleshooting inquiry:\", response_troubleshooting)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkC26vy_8fXG"
      },
      "source": [
        "### Exercise 3: Crafting Contextual Prompts\n",
        "\n",
        "**Task:** Create your own prompts for a different scenario, such as a travel recommendation, a financial advice request, or a personal goal-setting inquiry. Include enough context to ensure the AI generates useful responses.\n",
        "\n",
        "**Your Contextual Prompts:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZUBFOXC8fXH"
      },
      "outputs": [],
      "source": [
        "# Example of a user-created prompt\n",
        "custom_prompt = \"\"\"\n",
        "I’m planning a trip to Japan and want to explore historical sites.\n",
        "Can you recommend must-see places and provide some tips for visiting these sites?\n",
        "\"\"\"\n",
        "\n",
        "# Generating the response\n",
        "response_custom = openai.Completion.create(\n",
        "    engine=\"gpt-4\",\n",
        "    prompt=custom_prompt,\n",
        "    max_tokens=150\n",
        ").choices[0].text.strip()\n",
        "\n",
        "# Displaying the response\n",
        "print(\"Response to custom prompt:\", response_custom)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrHF6sqQ8fXH"
      },
      "source": [
        "### Reflection:\n",
        "\n",
        "How did the context you provided in your custom prompt affect the AI’s response? Was the response relevant and helpful? What improvements could you make to the prompt for better results?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J67G0Wb68fXH"
      },
      "source": [
        "## Section 4: Common Pitfalls and Best Practices\n",
        "\n",
        "As you become more proficient with contextual prompting, it’s important to be aware of common pitfalls and best practices. This section will help you avoid mistakes and ensure that your prompts are as effective as possible.\n",
        "\n",
        "### Common Pitfalls:\n",
        "1. **Overloading with Information:** Providing too much context can overwhelm the AI and lead to diluted responses.\n",
        "2. **Irrelevant Context:** Including details that aren't directly related to the task can confuse the AI.\n",
        "3. **Assuming AI's Prior Knowledge:** Expecting the AI to know something that isn't included in the prompt can result in incomplete answers.\n",
        "\n",
        "### Best Practices:\n",
        "- **Be Specific:** Include only the details necessary for the task at hand.\n",
        "- **Prioritize Information:** Start with the most critical information and add secondary details as needed.\n",
        "- **Test and Refine:** Always test your prompts and be prepared to iterate on them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5cylPjZ8fXH"
      },
      "source": [
        "### Interactive Quiz: Spot the Mistake\n",
        "\n",
        "Below are examples of prompts with potential pitfalls. Identify the mistake and suggest a revision.\n",
        "\n",
        "**Prompt 1:** \"I'm having a terrible day, and everything seems to be going wrong. Can you help me?\"\n",
        "\n",
        "**Mistake:**\n",
        "\n",
        "**Suggested Revision:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GabeNp_I8fXH"
      },
      "outputs": [],
      "source": [
        "# Example revision\n",
        "revised_prompt_1 = \"\"\"\n",
        "I'm feeling overwhelmed because I missed my train, my boss is unhappy with my work, and I have a lot of tasks to complete today.\n",
        "Can you suggest some quick ways to improve my mood and productivity?\n",
        "\"\"\"\n",
        "print(\"Revised Prompt 1:\", revised_prompt_1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dydh8kA78fXI"
      },
      "source": [
        "### Summary:\n",
        "\n",
        "- **Less is More:** Keep your prompts concise but contextually rich.\n",
        "- **Iterate:** Test and refine your prompts to see what works best.\n",
        "- **Context is Key:** The right context can turn a generic response into a highly relevant one.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpS8-N8R8fXI"
      },
      "source": [
        "## Conclusion and Next Steps\n",
        "\n",
        "Congratulations on completing Lab 5: Contextual Prompting! By now, you should have a solid understanding of how to use context effectively in prompts and manage long prompts by focusing on essential information.\n",
        "\n",
        "**Key Takeaways:**\n",
        "- Context is a powerful tool in prompt engineering. It can guide the AI to produce more accurate and relevant responses.\n",
        "- Managing long prompts involves identifying and including only the most crucial details.\n",
        "\n",
        "**Next Steps:**\n",
        "- Continue practicing contextual prompting with different scenarios.\n",
        "- Experiment with more complex contexts and refine your prompts accordingly.\n",
        "- Share your insights with your peers and learn from their approaches.\n",
        "\n",
        "In the next lab, we’ll explore **Dynamic Prompting with External APIs**—integrating real-time data into your prompts to make them even more powerful and responsive.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV5p95d18fXI"
      },
      "source": [
        "### Final Discussion:\n",
        "\n",
        "How has your understanding of contextual prompting evolved through this lab? What was the most challenging aspect, and how did you overcome it? Share your thoughts and experiences with the class.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}