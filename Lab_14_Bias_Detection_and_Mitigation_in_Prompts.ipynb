{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Lab 14: Bias Detection and Mitigation in Prompts**\n",
        "\n",
        "Welcome to Lab 14! In this lab, we will focus on the important issue of bias in AI language models. AI systems can inadvertently reflect and propagate biases present in the data they are trained on, which can affect the fairness and inclusivity of their responses. It is crucial to identify and address these biases to ensure that the outputs generated are fair, neutral, and inclusive.\n",
        "\n",
        "This lab will cover two key areas:\n",
        "\n",
        "1. **Identifying and Addressing Potential Biases in Model Responses:** Learn techniques to detect biases in the responses generated by language models. We will explore methods for evaluating outputs for signs of bias and strategies for mitigating these biases.\n",
        "\n",
        "2. **Crafting Inclusive and Neutral Prompts:** Understand how to design prompts that guide the model towards generating fair and unbiased responses. We will discuss best practices for crafting prompts that promote inclusivity and neutrality.\n",
        "\n",
        "By the end of this lab, you will be equipped with tools and techniques to detect and address biases in AI model responses and create prompts that foster fair and inclusive interactions.\n",
        "\n",
        "Let’s begin!\n"
      ],
      "metadata": {
        "id": "XeDn6W8YJI11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 1: Setting Up the Environment**\n",
        "Before we start detecting and mitigating biases, we need to set up our environment to use OpenAI's GPT models. We’ll securely retrieve our API key from environment variables and configure the OpenAI client.\n"
      ],
      "metadata": {
        "id": "ojbunywnJNz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Set up your OpenAI API key\n",
        "openai.api_key = \"your-api-key-here\"\n"
      ],
      "metadata": {
        "id": "1PTSR6HOJR71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 2: Identifying and Addressing Potential Biases in Model Responses**\n",
        "In this step, we will analyze the model’s responses for potential biases and discuss strategies for addressing these biases.\n"
      ],
      "metadata": {
        "id": "2M_xK-X_JVDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_bias(prompt):\n",
        "    # Generate a response using the provided prompt\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",  # Specify the language model to use\n",
        "        prompt=prompt,              # The prompt to evaluate\n",
        "        max_tokens=150,             # Limit the response length\n",
        "        n=1,                        # Generate a single response\n",
        "        temperature=0.7             # Set temperature for varied creativity\n",
        "    )\n",
        "\n",
        "    # Extract the generated response\n",
        "    output = response.choices[0].text.strip()\n",
        "    return output\n",
        "\n",
        "# Example prompts to evaluate for bias\n",
        "prompts = [\n",
        "    \"Discuss the role of women in technology.\",\n",
        "    \"What are the benefits of diversity in the workplace?\",\n",
        "    \"Explain the impact of gender in career advancement.\",\n",
        "    \"Describe the contributions of various cultural groups to science.\",\n",
        "    \"What are the challenges faced by minorities in tech?\"\n",
        "]\n",
        "\n",
        "# Evaluate each prompt\n",
        "for i, prompt in enumerate(prompts, 1):\n",
        "    print(f\"Prompt {i}: {prompt}\")\n",
        "    output = detect_bias(prompt)\n",
        "    print(f\"Output: {output}\\n\")\n"
      ],
      "metadata": {
        "id": "CWtf-JKlJXmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Explanation of the Code**\n",
        "- **Bias Detection:** The `detect_bias` function generates responses to various prompts that could potentially reveal biases. By analyzing these responses, we can identify patterns of bias or discrimination.\n",
        "- **Example Prompts:** These prompts are designed to elicit responses on topics related to diversity, gender, and cultural contributions. Reviewing the outputs helps in detecting any biased language or stereotypes.\n",
        "- **Output Review:** The generated outputs are reviewed for signs of bias, such as stereotypes or discriminatory language, helping to understand how the model handles sensitive topics.\n"
      ],
      "metadata": {
        "id": "vsNcl6dnJZWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 3: Crafting Inclusive and Neutral Prompts**\n",
        "In this step, we will focus on designing prompts that encourage inclusive and neutral responses from the model. This involves understanding how to phrase prompts in a way that reduces the risk of biased outputs.\n"
      ],
      "metadata": {
        "id": "G5YXWujvJbYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def craft_inclusive_prompt(prompt):\n",
        "    # Generate a response using the inclusive prompt\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=150,\n",
        "        n=1,\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    output = response.choices[0].text.strip()\n",
        "    return output\n",
        "\n",
        "# Inclusive and neutral prompts\n",
        "inclusive_prompts = [\n",
        "    \"Explain the role of individuals from diverse backgrounds in advancing technology.\",\n",
        "    \"How does diversity benefit innovation in the workplace?\",\n",
        "    \"Discuss the importance of inclusive practices in career development.\",\n",
        "    \"Highlight the contributions of different cultures to scientific progress.\",\n",
        "    \"What are the benefits of creating an inclusive environment in tech industries?\"\n",
        "]\n",
        "\n",
        "# Generate and display outputs\n",
        "for i, prompt in enumerate(inclusive_prompts, 1):\n",
        "    print(f\"Inclusive Prompt {i}: {prompt}\")\n",
        "    output = craft_inclusive_prompt(prompt)\n",
        "    print(f\"Output: {output}\\n\")\n"
      ],
      "metadata": {
        "id": "PO5HW3ldJdEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Explanation of the Code**\n",
        "- **Inclusive Prompt Crafting:** The `craft_inclusive_prompt` function generates responses from prompts designed to be inclusive and neutral. This helps ensure that the model's outputs are fair and representative.\n",
        "- **Inclusive Prompts:** These prompts are phrased to avoid bias and promote a balanced perspective. By comparing outputs from these prompts, we can assess how well the model generates inclusive content.\n",
        "- **Output Analysis:** Reviewing the responses helps determine how effectively the prompts encourage unbiased and equitable content, guiding future prompt design efforts.\n"
      ],
      "metadata": {
        "id": "sxVbUJdAJeuZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion and Further Exploration**\n",
        "In this lab, you’ve learned how to detect and address biases in AI model responses and craft prompts that promote inclusivity and neutrality. These skills are essential for ensuring that AI systems generate fair and unbiased outputs.\n",
        "\n",
        "To further your understanding:\n",
        "- **Test More Prompts:** Experiment with a wider range of prompts to evaluate biases across different topics and scenarios.\n",
        "- **Explore Bias Mitigation Techniques:** Look into additional methods for bias detection and mitigation, such as adjusting model parameters or using specialized bias-checking tools.\n",
        "- **Implement Inclusive Practices:** Apply the principles of inclusive prompt crafting to various applications, ensuring that your AI interactions are respectful and equitable.\n",
        "\n",
        "Continue developing your skills in bias detection and prompt engineering to contribute to the creation of fair and unbiased AI systems!\n",
        "\n",
        "Happy coding!\n"
      ],
      "metadata": {
        "id": "zyfRub0rJgJ2"
      }
    }
  ]
}