{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Prompt Engineering\n",
        "In this lesson, you will practice essential prompting principles and related tactics to be able to write effective prompts and leverage OpenAI's APIs using their LLMs (large language models).\n",
        "\n",
        "## Setting up your environment\n",
        "\n",
        "First, you must install and update the Python libraries required for working with OpenAI APIs"
      ],
      "metadata": {
        "id": "2ox59uMJ7Q6K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUvOTfMi7Bxo"
      },
      "outputs": [],
      "source": [
        "# suppress the verbose output by usnig the %%capture annotation\n",
        "%%capture\n",
        "\n",
        "# update or install the necessary libraries\n",
        "!pip install --upgrade openai\n",
        "!pip install --upgrade python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, load the API key and relevant Python libaries."
      ],
      "metadata": {
        "id": "wT6lT7O89Uu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "import IPython\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "1ORhAcAL7h8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To load environment variables, you can use anything you like but I used python-dotenv. Just create a .env file with your OPENAI_API_KEY then load it."
      ],
      "metadata": {
        "id": "74-XBNRS7lK-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making your first API call\n",
        "\n",
        "Now that we are all set up, let's make a simple API call to OpenAI's  `gpt-4`  model to see how to do it in the simplest way. We will explore more complex techniques and use cases in the lab exercises that follow."
      ],
      "metadata": {
        "id": "NwbWFZsr7qg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = \"gpt-4\"\n",
        "\n",
        "response = openai.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an AI research assistant helping scholars understand different topics in a simple manner. You use technical and scientific terms but explain them in a straightforward way, breaking down complex topics into simple points.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Hello, who are you?\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Hi! I am an AI research assistant. How can I help you?\"},\n",
        "        {\"role\": \"user\", \"content\": \"Can you describe the lifecycle of a star like the Sun?\"}\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n"
      ],
      "metadata": {
        "id": "1fGQJikK7tvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the API ran succesfully, you'll NOT see any error messages. Remember, it is not a chatbot agent, but a backend API. You will have to write code to print the putput to a location of your choice (web, app, console, etc.) and it will not be done automatically.\n",
        "\n",
        "So, let's print the response:"
      ],
      "metadata": {
        "id": "T_nIM2Qs7wr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response.choices[0].message.content"
      ],
      "metadata": {
        "id": "wjXsWmoL7x0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you think that the response is not properly formatted and your users will ahve a hard time understanding it, you're right.\n",
        "\n",
        "So, why not we beautify the response by formatting it properly?"
      ],
      "metadata": {
        "id": "ikTjJZ4b_dUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IPython.display.Markdown(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "Y1FBrXqj_jEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Helper Function\n",
        "\n",
        "Everytime we wish to write prompt, invoke the model API, receive the output, and format the output, we will have repeat the same process again. As this will a typicall API call, let's make a helper function to make live simpler - we'll call this helpr function `get_response()`\n",
        "\n",
        "This helper function will allow us to easily use prompts and print the generated outputs."
      ],
      "metadata": {
        "id": "lE69EM1uHUn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(prompt, model=\"gpt-4\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0,  # Controls the randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]\n"
      ],
      "metadata": {
        "id": "W_U2Vf1lIA18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompting Best-practices to Follow\n",
        "\n",
        "Like any conversation, prompti engineering also follows only two essential best practices. These are:\n",
        "\n",
        "1.   Write clear and specific instructions\n",
        "2.   Give the model time to “think”\n",
        "\n",
        "All other principles and best practices emerge from these two only. Let's see them one by one to understand how they can help us become better prompt engineering developers."
      ],
      "metadata": {
        "id": "0ukzzOm8_zpA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1: Writing clear and specific instructions\n",
        "\n",
        "Clear and specific instructions can be written if you follow a few tips. We list the most important ones for you to practice.\n",
        "\n",
        "#### Tip #1: Use delimiters\n",
        "Delimiters like **`** , **\"**,  **\"\"\",** **< >**, **\\<tag> \\</tag>**, **:**, etc. -- to clearly indicate distinct parts of the input. A delimiter can be anything that separates one part of your input form other. For example, your prompt may look like\n",
        "\n",
        "`text = f\"\"\"Some long text you wish to summarize\"\"\"`\n",
        "\n",
        "`prompt = f\"\"\"Summarize the text delimited by triple backticks into a single sentence. ```{text}```\"\"\" `\n",
        "\n",
        "Let's see this with the help of an example."
      ],
      "metadata": {
        "id": "H1sznV5EBqWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "You should express what you want a model to do by \\\n",
        "providing instructions that are as clear and \\\n",
        "specific as you can possibly make them. \\\n",
        "This will guide the model towards the desired output, \\\n",
        "and reduce the chances of receiving irrelevant \\\n",
        "or incorrect responses. Don't confuse writing a \\\n",
        "clear prompt with writing a short prompt. \\\n",
        "In many cases, longer prompts provide more clarity \\\n",
        "and context for the model, which can lead to \\\n",
        "more detailed and relevant outputs.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the text delimited by triple backticks \\\n",
        "into a single sentence.\n",
        "```{text}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_response(prompt)\n",
        "\n",
        "# Beuatify the response\n",
        "IPython.display.Markdown(response)"
      ],
      "metadata": {
        "id": "WhnJjGG9HB_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#### Tip #2: Request for a structured output\n",
        "Your OpenAI model is capable of prodcing structured textual output that can easily be parsed by other software. it can produce the response in structured formats such as JSON, XML, HTML, or the plain-vanilla CSV.\n",
        "\n",
        "If you request your model to return the response in a structured format, you'll be doing your team a great service! Let's check this with an example.\n"
      ],
      "metadata": {
        "id": "zlfvlK9ZHAD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Generate a list of three best selling books for children \\\n",
        "in the age group of twelve to fifteen \\\n",
        "with their authors, country, year of publishing, and a brief summary within 50 words.\n",
        "Provide them in JSON format with the following keys:\n",
        "ISBN, title, author, genre, summary.\n",
        "\"\"\"\n",
        "\n",
        "response = get_response(prompt)\n",
        "\n",
        "IPython.display.Markdown(response)"
      ],
      "metadata": {
        "id": "JtOFD49_JzfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tip #3: Ask the model to check whether conditions are satisfied\n",
        "\n",
        "Like any intelligent helper, you can direct your model to see if the reposne satisfies the conditions you've set out in the prompt. And like all intelligent helpers, the model will make a best effort to comply."
      ],
      "metadata": {
        "id": "uzaK8yDDJRNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = f\"\"\"\n",
        "Making a cup of tea is easy! First, you need to get some \\\n",
        "water boiling. While that's happening, \\\n",
        "grab a cup and put a tea bag in it. Once the water is \\\n",
        "hot enough, just pour it over the tea bag. \\\n",
        "Let it sit for a bit so the tea can steep. After a \\\n",
        "few minutes, take out the tea bag. If you \\\n",
        "like, you can add some sugar or milk to taste. \\\n",
        "And that's it! You've got yourself a delicious \\\n",
        "cup of tea to enjoy.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "You will be provided with text delimited by triple quotes.\n",
        "If it contains a sequence of instructions, \\\n",
        "re-write those instructions in the following format:\n",
        "\n",
        "STEPS\n",
        "#1 - ...\n",
        "#2 - ...\n",
        "...\n",
        "#N - ...\n",
        "\n",
        "If the text does not contain a sequence of instructions, \\\n",
        "then simply write \\\"No steps provided.\\\"\n",
        "\n",
        "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "\n",
        "response = get_response(prompt)\n",
        "\n",
        "IPython.display.Markdown(response)"
      ],
      "metadata": {
        "id": "pFBlHVi1KlSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's another example, where there are no steps in the prompt. Let's see how the model worls this time."
      ],
      "metadata": {
        "id": "dxPtjkdXMov7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text_2 = f\"\"\"\n",
        "The sun is shining brightly today, and the birds are \\\n",
        "singing. It's a beautiful day to go for a \\\n",
        "walk in the park. The flowers are blooming, and the \\\n",
        "trees are swaying gently in the breeze. People \\\n",
        "are out and about, enjoying the lovely weather. \\\n",
        "Some are having picnics, while others are playing \\\n",
        "games or simply relaxing on the grass. It's a \\\n",
        "perfect day to spend time outdoors and appreciate the \\\n",
        "beauty of nature.\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "You will be provided with text delimited by triple quotes.\n",
        "If it contains a sequence of instructions, \\\n",
        "re-write those instructions in the following format:\n",
        "\n",
        "STEPS\n",
        "#1 - ...\n",
        "#2 - ...\n",
        "...\n",
        "#N - ...\n",
        "\n",
        "If the text does not contain a sequence of instructions, \\\n",
        "then simply write \\\"No steps provided.\\\"\n",
        "\n",
        "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "\n",
        "response = get_response(prompt)\n",
        "\n",
        "IPython.display.Markdown(response)"
      ],
      "metadata": {
        "id": "edA4pujeMzcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tip #4: Give Examples\n",
        "\n",
        "When you give your model some examples of expected output, you train its output in the direction you want it to take. This is called **One-shot** or **Few-shot** prompting. We will discuss about them in detail in the labs that follow, but let's look at an example right away."
      ],
      "metadata": {
        "id": "Jb3rECzNJSZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt = f\"\"\"\n",
        "Your task is to answer in a consistent style.\n",
        "\n",
        ": Teach me about patience.\n",
        "\n",
        ": The river that carves the deepest \\\n",
        "valley flows from a modest spring; the \\\n",
        "grandest symphony originates from a single note; \\\n",
        "the most intricate tapestry begins with a solitary thread.\n",
        "\n",
        ": Teach me about resilience.\n",
        "\"\"\"\n",
        "\n",
        "response = get_response(prompt)\n",
        "\n",
        "IPython.display.Markdown(response)"
      ],
      "metadata": {
        "id": "wvkpN2FBKl7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2: Give the model time to “think”\n",
        "\n",
        "Any LLM would take some time to process your request, search its embeddings to find the most likelyn response, generate the response one token at a time, and return the result back to you. This all takes time, and if you don;t give it the time to \"think\", you'll make the mistake of overwhelming it by repeated requests.\n",
        "\n",
        "Here are a couple of tips to expedite its work and help it think the \"right way.\"\n",
        "\n",
        "#### Tip #1: Specify the steps required to complete a task\n",
        "\n",
        "Relying on the model to figure out the best way to complete a task will only add to its burden. You can take some responsibility by telling it the steps to follow and speed up content generation. Here's how you can do it:"
      ],
      "metadata": {
        "id": "PbtqD8tNNefs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = f\"\"\"\n",
        "In a charming village, siblings Jack and Jill set out on \\\n",
        "a quest to fetch water from a hilltop \\\n",
        "well. As they climbed, singing joyfully, misfortune \\\n",
        "struck—Jack tripped on a stone and tumbled \\\n",
        "down the hill, with Jill following suit. \\\n",
        "Though slightly battered, the pair returned home to \\\n",
        "comforting embraces. Despite the mishap, \\\n",
        "their adventurous spirits remained undimmed, and they \\\n",
        "continued exploring with delight.\n",
        "\"\"\"\n",
        "# example 1\n",
        "prompt_1 = f\"\"\"\n",
        "Perform the following actions:\n",
        "1 - Summarize the following text delimited by triple \\\n",
        "backticks with 1 sentence.\n",
        "2 - Translate the summary into French.\n",
        "3 - List each name in the French summary.\n",
        "4 - Output a json object that contains the following \\\n",
        "keys: french_summary, num_names.\n",
        "\n",
        "Separate your answers with line breaks.\n",
        "\n",
        "Text:\n",
        "```{text}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_response(prompt_1)\n",
        "\n",
        "IPython.display.Markdown(response)"
      ],
      "metadata": {
        "id": "d_CqRn-MOmfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Ask for output in a specified format\n",
        "\n",
        "By combining the Tip #2 from above with this tip, you can further simplify the work of the model."
      ],
      "metadata": {
        "id": "h1i6dxKDOxiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_2 = f\"\"\"\n",
        "Your task is to perform the following actions:\n",
        "1 - Summarize the following text delimited by\n",
        "  <> with 1 sentence.\n",
        "2 - Translate the summary into French.\n",
        "3 - List each name in the French summary.\n",
        "4 - Output a json object that contains the\n",
        "  following keys: french_summary, num_names.\n",
        "\n",
        "Use the following format:\n",
        "Text:\n",
        "Text:\n",
        "```{text}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_response(prompt_2)\n",
        "\n",
        "IPython.display.Markdown(response)"
      ],
      "metadata": {
        "id": "AyoHIR24P9Mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tip #2: Instruct to double-check\n",
        "\n",
        "You can always tell the model to work out its own solution, double chek it, before rushing to a conclusion."
      ],
      "metadata": {
        "id": "MKIK4pknQM7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_1 = f\"\"\"\n",
        "Determine if the student's solution is correct or not.\n",
        "\n",
        "Question:\n",
        "I'm building a solar power installation and I need \\\n",
        " help working out the financials.\n",
        "- Land costs\n",
        "250 / square foot\n",
        "- I negotiated a contract for maintenance that will cost \\\n",
        "me a flat\n",
        "10 / square \\\n",
        "foot\n",
        "What is the total cost for the first year of operations\n",
        "as a function of the number of square feet.\n",
        "\n",
        "Student's Solution:\n",
        "Let x be the size of the installation in square feet.\n",
        "Costs:\n",
        "1. Land cost: 100x\n",
        "2. Solar panel cost: 250x\n",
        "3. Maintenance cost: 100,000 + 100x\n",
        "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
        "\"\"\"\n",
        "\n",
        "response = get_response(prompt_1)\n",
        "\n",
        "IPython.display.Markdown(response)"
      ],
      "metadata": {
        "id": "NW9UnHM9Qr_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see for yourself that the solution is not up to the mark - may be its outright wrong, or some aspects are misstated.\n",
        "\n",
        "We can fix this by instructing the model to work out its own solution first."
      ],
      "metadata": {
        "id": "Zj7NRPuOQ_7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_2 = f\"\"\"\n",
        "Your task is to determine if the student's solution \\\n",
        "is correct or not.\n",
        "To solve the problem do the following:\n",
        "- First, work out your own solution to the problem.\n",
        "- Then compare your solution to the student's solution \\\n",
        "and evaluate if the student's solution is correct or not.\n",
        "Don't decide if the student's solution is correct until\n",
        "you have done the problem yourself.\n",
        "\n",
        "Use the following format:\n",
        "Question:\n",
        "```\n",
        "question here\n",
        "```\n",
        "Student's solution:\n",
        "```\n",
        "student's solution here\n",
        "```\n",
        "Actual solution:\n",
        "```\n",
        "steps to work out the solution and your solution here\n",
        "```\n",
        "Is the student's solution the same as actual solution \\\n",
        "just calculated:\n",
        "```\n",
        "yes or no\n",
        "```\n",
        "Student grade:\n",
        "```\n",
        "correct or incorrect\n",
        "```\n",
        "\n",
        "Question:\n",
        "```\n",
        "I'm building a solar power installation and I need help \\\n",
        "working out the financials.\n",
        "- Land costs\n",
        "250 / square foot\n",
        "- I negotiated a contract for maintenance that will cost \\\n",
        "me a flat\n",
        "10 / square \\\n",
        "foot\n",
        "What is the total cost for the first year of operations \\\n",
        "as a function of the number of square feet.\n",
        "```\n",
        "Student's solution:\n",
        "```\n",
        "Let x be the size of the installation in square feet.\n",
        "Costs:\n",
        "1. Land cost: 100x\n",
        "2. Solar panel cost: 250x\n",
        "3. Maintenance cost: 100,000 + 100x\n",
        "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
        "```\n",
        "Actual solution:\n",
        "\"\"\"\n",
        "\n",
        "response = get_response(prompt_2)\n",
        "\n",
        "IPython.display.Markdown(response)"
      ],
      "metadata": {
        "id": "CtoZnT65RLdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment more to know more!\n",
        "\n",
        "To use the OpenAI API outside of this classroom\n",
        "\n",
        "To install the OpenAI Python library:\n",
        "\n",
        "```\n",
        "!pip install openai\n",
        "```\n",
        "The library needs to be configured with your account's secret key, which is available in your OpenAI account.\n",
        "\n",
        "You can either set it as the `OPENAI_API_KEY` environment variable before using the library:\n",
        "\n",
        "```\n",
        "!export OPENAI_API_KEY='sk-...'\n",
        "```\n",
        "Or, set variable `openai.api_key` to its value:\n",
        "\n",
        "```\n",
        "import openai\n",
        "openai.api_key = \"sk-...\"\n",
        "```\n",
        "\n",
        "**A note about the backslash**\n",
        "\n",
        "In the course, we are using a backslash `\\` to make the text fit on the screen without inserting newline '\\n' characters within our texts or prompts.\n",
        "GPT-3 isn't really affected whether you insert newline characters or not. But when working with LLMs in general, you may consider whether newline characters in your prompt may affect the model's performance."
      ],
      "metadata": {
        "id": "0U1xrTKdRaVQ"
      }
    }
  ]
}